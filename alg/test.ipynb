{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"test.json\", lines=True)\n",
    "df.transpose()\n",
    "df[\"44e8d2a0-7e01-450b-90b0-beb7400d2c1e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"44e8d2a0-7e01-450b-90b0-beb7400d2c1e\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:, :453]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"annotations.csv\", sep=\"\\t\")\n",
    "df2 = df2.iloc[:453]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "landmarks = {\"А\": [], \"Б\": [], \"В\": [], \"Г\": [], \"Д\": [], \"Е\": [], \"Ё\": [], \"Ж\": [], \"З\": [], \"И\": [], \"Й\": [], \"К\": [], \"Л\": [], \"М\": [], \"Н\": [], \"О\": [], \"П\": [], \"Р\": [], \"С\": [], \"Т\": [], \"У\": [], \"Ф\": [], \"Х\": [], \"Ц\": [], \"Ч\": [], \"Ш\": [], \"Щ\": [], \"Ъ\": [], \"Ы\": [], \"Ь\": [], \"Э\": [], \"Ю\": [], \"Я\": []}\n",
    "for col in df.columns:\n",
    "    print(f\"on col {col}\")\n",
    "    landmarks_for_col = []\n",
    "    for j in range(len(df[col][0])):\n",
    "        landmarks_for_frame = []\n",
    "        print(f\"on frame {j}\")\n",
    "        for i in range(4, 21, 4):\n",
    "            landmarks_for_frame.append([df[col][0][j][\"hand 1\"][i][\"x\"], df[col][0][j][\"hand 1\"][i][\"y\"]])\n",
    "        landmarks_for_col.append(landmarks_for_frame)\n",
    "    print(f\"len {len(landmarks_for_frame)}\")\n",
    "    landmarks[df2[\"text\"][list(df.columns).index(col)]].append(landmarks_for_col)\n",
    "\n",
    "landmarks[\"А\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks[\"А\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = {\"4x\": [], \"4y\": [], \"8x\": [], \"8y\": [], \"12x\": [], \"12y\": [], \"16x\": [], \"16y\": [], \"20x\": [], \"20y\": [], \"letter\": []}\n",
    "\n",
    "for k in landmarks.keys():\n",
    "    for lm in landmarks[k]:\n",
    "        for frame in lm:\n",
    "            ndf[\"4x\"].append(frame[0][0])\n",
    "            ndf[\"4y\"].append(frame[0][1])\n",
    "            ndf[\"8x\"].append(frame[1][0])\n",
    "            ndf[\"8y\"].append(frame[1][1])\n",
    "            ndf[\"12x\"].append(frame[2][0])\n",
    "            ndf[\"12y\"].append(frame[2][1])\n",
    "            ndf[\"16x\"].append(frame[3][0])\n",
    "            ndf[\"16y\"].append(frame[3][1])\n",
    "            ndf[\"20x\"].append(frame[4][0])\n",
    "            ndf[\"20y\"].append(frame[4][1])\n",
    "            ndf[\"letter\"].append(k)\n",
    "\n",
    "ndf = pd.DataFrame(ndf)\n",
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1 - А, Е/Ё, Ж, Й, О, Ч, Ю\n",
    "2 - Б, Д, З, К, С, Ф, Х, Э, Я\n",
    "3 - В, И, Н, Р, У, Ц, Ш/Щ, Ь, Ы, Ъ\n",
    "4 - Г, Л, М, П, Т\n",
    "\"\"\"\n",
    "\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace([\"А\", \"Е\", \"Ё\", \"Ж\", \"Й\", \"О\", \"Ч\", \"Ю\"], 0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace([\"Б\", \"Д\", \"З\", \"К\", \"С\", \"Ф\", \"Х\", \"Э\", \"Я\"], 1)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace([\"В\", \"И\", \"Н\", \"Р\", \"У\", \"Ц\", \"Ш\", \"Щ\", \"Ь\", \"Ы\", \"Ъ\"], 2)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace([\"Г\", \"Л\", \"М\", \"П\", \"Т\"], 3)\n",
    "\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"А\", 0.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Б\", 1.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"В\", 2.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Г\", 3.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Д\", 4.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Е\", 5.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ё\", 5.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ж\", 6.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"З\", 7.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"И\", 8.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Й\", 9.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"К\", 10.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Л\", 11.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"М\", 12.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Н\", 13.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"О\", 14.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"П\", 15.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Р\", 16.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"С\", 17.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Т\", 18.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"У\", 19.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ф\", 20.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Х\", 21.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ц\", 22.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ч\", 23.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ш\", 24.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Щ\", 25.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ъ\", 26.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ы\", 27.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ь\", 28.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Э\", 29.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ю\", 30.0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace(\"Я\", 31.0)\n",
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SignLanguageNetPart1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SignLanguageNetPart1, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the neural network\n",
    "model = SignLanguageNetPart1()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ndf.drop(\"letter\", axis = 1)\n",
    "y = ndf[\"letter\"]\n",
    "\n",
    "x = x.values\n",
    "y = y.values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch import FloatTensor, LongTensor\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "x_train = FloatTensor(x_train)\n",
    "x_test = FloatTensor(x_test)\n",
    "\n",
    "y_train = LongTensor(y_train)\n",
    "y_test = LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1500\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_pred = model.forward(x_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss.detach().numpy())\n",
    "\n",
    "    if i % 10 == 0: print(f\"epoch {i} had loss {loss}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel(\"loss/error\")\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import no_grad\n",
    "\n",
    "with no_grad():\n",
    "  y_eval = model.forward(x_test)\n",
    "  loss = criterion(y_eval, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "with no_grad():\n",
    "  for i, data in enumerate(x_test):\n",
    "    y_val = model.forward(data)\n",
    "\n",
    "    print(f'{i+1}.)  {y_test[i]} \\t {y_val.argmax().item()}')\n",
    "\n",
    "    # Correct or not\n",
    "    if y_val.argmax().item() == y_test[i]:\n",
    "      correct +=1\n",
    "\n",
    "print(f'We got {correct} correct!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"./modelpart1.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
