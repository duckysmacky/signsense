{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"test.json\", lines=True)\n",
    "df.transpose()\n",
    "df[\"44e8d2a0-7e01-450b-90b0-beb7400d2c1e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"44e8d2a0-7e01-450b-90b0-beb7400d2c1e\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:, :453]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"annotations.csv\", sep=\"\\t\")\n",
    "df2 = df2.iloc[:453]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# создаём таблицу (в виде словаря)\n",
    "landmarks = {\"А\": [], \"Б\": [], \"В\": [], \"Г\": [], \"Д\": [], \"Е\": [], \"Ё\": [], \"Ж\": [], \"З\": [], \"И\": [],\n",
    "             \"Й\": [], \"К\": [], \"Л\": [], \"М\": [], \"Н\": [], \"О\": [], \"П\": [], \"Р\": [], \"С\": [], \"Т\": [],\n",
    "             \"У\": [], \"Ф\": [], \"Х\": [], \"Ц\": [], \"Ч\": [], \"Ш\": [], \"Щ\": [], \"Ъ\": [], \"Ы\": [], \"Ь\": [],\n",
    "             \"Э\": [], \"Ю\": [], \"Я\": []\n",
    "}\n",
    "for col in df.columns:\n",
    "    landmarks_for_col = []\n",
    "    # для каждого кадра в каждом видео изначального датасета\n",
    "    for j in range(len(df[col][0])):\n",
    "        landmarks_for_frame = []\n",
    "        # берём координаты x и y точек руки\n",
    "        for i in range(0, 21):\n",
    "            landmarks_for_frame.append([df[col][0][j][\"hand 1\"][i][\"x\"], df[col][0][j][\"hand 1\"][i][\"y\"]])\n",
    "        landmarks_for_col.append(landmarks_for_frame)\n",
    "    # записываем координаты в таблицу\n",
    "    landmarks[df2[\"text\"][list(df.columns).index(col)]].append(landmarks_for_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks[\"А\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# новая таблица\n",
    "ndf = {\n",
    "    \"0x\": [], \"0y\": [], \"1x\": [], \"1y\": [], \"2x\": [], \"2y\": [], \"3x\": [], \"3y\": [], \"4x\": [], \"4y\": [],\n",
    "    \"5x\": [], \"5y\": [], \"6x\": [], \"6y\": [], \"7x\": [], \"7y\": [], \"8x\": [], \"8y\": [], \"9x\": [], \"9y\": [],\n",
    "    \"10x\": [], \"10y\": [], \"11x\": [], \"11y\": [], \"12x\": [], \"12y\": [], \"13x\": [], \"13y\": [], \"14x\": [], \"14y\": [],\n",
    "    \"15x\": [], \"15y\": [], \"16x\": [], \"16y\": [], \"17x\": [], \"17y\": [], \"18x\": [], \"18y\": [], \"19x\": [], \"19y\": [],\n",
    "    \"20x\": [], \"20y\": [],\n",
    "    \"letter\": []\n",
    "}\n",
    "\n",
    "# преобразуем в нужный вид\n",
    "for k in landmarks.keys():\n",
    "    for lm in landmarks[k]:\n",
    "        for frame in lm:\n",
    "            ndf[\"0x\"].append(frame[0][0])\n",
    "            ndf[\"0y\"].append(frame[0][1])\n",
    "            ndf[\"1x\"].append(frame[1][0])\n",
    "            ndf[\"1y\"].append(frame[1][1])\n",
    "            ndf[\"2x\"].append(frame[2][0])\n",
    "            ndf[\"2y\"].append(frame[2][1])\n",
    "            ndf[\"3x\"].append(frame[3][0])\n",
    "            ndf[\"3y\"].append(frame[3][1])\n",
    "            ndf[\"4x\"].append(frame[4][0])\n",
    "            ndf[\"4y\"].append(frame[4][1])\n",
    "            ndf[\"5x\"].append(frame[5][0])\n",
    "            ndf[\"5y\"].append(frame[5][1])\n",
    "            ndf[\"6x\"].append(frame[6][0])\n",
    "            ndf[\"6y\"].append(frame[6][1])\n",
    "            ndf[\"7x\"].append(frame[7][0])\n",
    "            ndf[\"7y\"].append(frame[7][1])\n",
    "            ndf[\"8x\"].append(frame[8][0])\n",
    "            ndf[\"8y\"].append(frame[8][1])\n",
    "            ndf[\"9x\"].append(frame[9][0])\n",
    "            ndf[\"9y\"].append(frame[9][1])\n",
    "            ndf[\"10x\"].append(frame[10][0])\n",
    "            ndf[\"10y\"].append(frame[10][1])\n",
    "            ndf[\"11x\"].append(frame[11][0])\n",
    "            ndf[\"11y\"].append(frame[11][1])\n",
    "            ndf[\"12x\"].append(frame[12][0])\n",
    "            ndf[\"12y\"].append(frame[12][1])\n",
    "            ndf[\"13x\"].append(frame[13][0])\n",
    "            ndf[\"13y\"].append(frame[13][1])\n",
    "            ndf[\"14x\"].append(frame[14][0])\n",
    "            ndf[\"14y\"].append(frame[14][1])\n",
    "            ndf[\"15x\"].append(frame[15][0])\n",
    "            ndf[\"15y\"].append(frame[15][1])\n",
    "            ndf[\"16x\"].append(frame[16][0])\n",
    "            ndf[\"16y\"].append(frame[16][1])\n",
    "            ndf[\"17x\"].append(frame[17][0])\n",
    "            ndf[\"17y\"].append(frame[17][1])\n",
    "            ndf[\"18x\"].append(frame[18][0])\n",
    "            ndf[\"18y\"].append(frame[18][1])\n",
    "            ndf[\"19x\"].append(frame[19][0])\n",
    "            ndf[\"19y\"].append(frame[19][1])\n",
    "            ndf[\"20x\"].append(frame[20][0])\n",
    "            ndf[\"20y\"].append(frame[20][1])\n",
    "            ndf[\"letter\"].append(k)\n",
    "\n",
    "ndf = pd.DataFrame(ndf)\n",
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# 1 - А, Е/Ё, Ж, Й, О, Ч, Ю\n",
    "# 2 - Б, Д, З, К, С, Ф, Х, Э, Я\n",
    "# 3 - В, И, Н, Р, У, Ц, Ш/Щ, Ь, Ы, Ъ\n",
    "# 4 - Г, Л, М, П, Т\n",
    "# \"\"\"\n",
    "\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace([\"А\", \"Е\", \"Ё\", \"Ж\", \"Й\", \"О\", \"Ч\", \"Ю\"], 0)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace([\"Б\", \"Д\", \"З\", \"К\", \"С\", \"Ф\", \"Х\", \"Э\", \"Я\"], 1)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace([\"В\", \"И\", \"Н\", \"Р\", \"У\", \"Ц\", \"Ш\", \"Щ\", \"Ь\", \"Ы\", \"Ъ\"], 2)\n",
    "# ndf[\"letter\"] = ndf[\"letter\"].replace([\"Г\", \"Л\", \"М\", \"П\", \"Т\"], 3)\n",
    "\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"А\", 0.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Б\", 1.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"В\", 2.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Г\", 3.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Д\", 4.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Е\", 5.0) #!\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ё\", 5.0) #!\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ж\", 6.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"З\", 7.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"И\", 8.0) #!\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Й\", 8.0) #!\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"К\", 9.0) \n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Л\", 10.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"М\", 11.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Н\", 12.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"О\", 13.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"П\", 14.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Р\", 15.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"С\", 16.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Т\", 17.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"У\", 18.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ф\", 19.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Х\", 20.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ц\", 21.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ч\", 22.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ш\", 23.0) #!\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Щ\", 23.0) #!\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ъ\", 24.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ы\", 25.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ь\", 26.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Э\", 27.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Ю\", 28.0)\n",
    "ndf[\"letter\"] = ndf[\"letter\"].replace(\"Я\", 29.0)\n",
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim import Adam\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class LetterClassification(nn.Module):\n",
    "#     def __init__(self, input_size, hidden1_size, hidden2_size, output_size):\n",
    "#         super(LetterClassification, self).__init__()\n",
    "#         self.input_layer = nn.Linear(input_size, hidden1_size)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.hl1 = nn.Linear(hidden1_size, hidden2_size)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         # self.hl2 = nn.Linear(hidden2_size, hidden3_size)\n",
    "#         # self.relu3 = nn.ReLU()\n",
    "#         self.output_layer = nn.Linear(hidden2_size, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.input_layer(x)\n",
    "#         out = self.relu1(out)\n",
    "#         out = self.hl1(out)\n",
    "#         out = self.relu2(out)\n",
    "#         # out = self.hl2(out)\n",
    "#         # out = self.relu3(out)\n",
    "#         out = self.output_layer(out)\n",
    "#         return out\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SignLanguageNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SignLanguageNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the neural network\n",
    "model = SignLanguageNet()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ndf.drop(\"letter\", axis = 1)\n",
    "y = ndf[\"letter\"]\n",
    "\n",
    "x = x.values\n",
    "y = y.values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch import FloatTensor, LongTensor\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "x_train = FloatTensor(x_train)\n",
    "x_test = FloatTensor(x_test)\n",
    "\n",
    "y_train = LongTensor(y_train)\n",
    "y_test = LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1500 # кол-во циклов/шагов тренировки\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    # делаем прогноз\n",
    "    y_pred = model.forward(x_train)\n",
    "    # мерим \"ошибку\"\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss.detach().numpy())\n",
    "\t# каждые 10 циклов выводим ошибку\n",
    "    if i % 10 == 0: print(f\"epoch {i} had loss {loss}\")\n",
    "\n",
    "\t# переходим к следующему шагу тренировки\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel(\"loss/error\")\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import no_grad\n",
    "\n",
    "with no_grad():\n",
    "  y_eval = model.forward(x_test)\n",
    "  loss = criterion(y_eval, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "with no_grad():\n",
    "  for i, data in enumerate(x_test):\n",
    "    y_val = model.forward(data)\n",
    "\n",
    "    print(f'{i+1}.)  {y_test[i]} \\t {y_val.argmax().item()}')\n",
    "\n",
    "    # Correct or not\n",
    "    if y_val.argmax().item() == y_test[i]:\n",
    "      correct +=1\n",
    "\n",
    "print(f'We got {correct} correct!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"./modelpart1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tosave = torch.load(\"modelpart1.pt\")\n",
    "tosave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "# Генериреум случайные числа\n",
    "X = torch.distributions.uniform.Uniform(-10000, \\\n",
    "\t10000).sample((30, 42))\n",
    "\n",
    "# Делаем модель оптимизированной\n",
    "traced_script_module = torch.jit.trace(model, X)\n",
    "traced_script_module_optimized = optimize_for_mobile(\\\n",
    "\ttraced_script_module)\n",
    "\n",
    "# Сохраняем оптимизированную модель\n",
    "traced_script_module_optimized._save_for_lite_interpreter(\\\n",
    "        \"modelultracool4.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
